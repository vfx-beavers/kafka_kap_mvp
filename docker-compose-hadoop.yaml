services:
  hadoop-namenode:
    image: apache/hadoop:3.4.1
    container_name: hadoop-namenode
    hostname: hadoop-namenode
    user: "root"
    restart: always
    platform: linux/amd64
    ports:
      - '9870:9870'
      - '9000:9000'
    deploy:
     resources:
       limits:
         cpus: "1.0"
         memory: "2g"
    shm_size: 10G
    environment:
      - CLUSTER_NAME=hadoop-cluster
    volumes:
      - ./hadoop/config/core-site.xml:/opt/hadoop/etc/hadoop/core-site.xml
      - ./hadoop/config/hdfs-site-namenode.xml:/opt/hadoop/etc/hadoop/hdfs-site.xml
      - ./hadoop/namenode_entrypoint.sh:/namenode_entrypoint.sh
    entrypoint: ["/bin/bash", "/namenode_entrypoint.sh"]
    command: ["hdfs", "namenode"]
    networks:
      - cheburnet


  hadoop-datanode-1:
    image: apache/hadoop:3.4.1
    container_name: hadoop-datanode-1
    hostname: hadoop-datanode-1
    user: "root"
    restart: always
    platform: linux/amd64
    deploy:
     resources:
       limits:
         cpus: "1.0"
         memory: "2g"
    shm_size: 10G
    depends_on:
      - hadoop-namenode
    ports:
      - "9864:9864"
      - "9970:9970"
    environment:
      - SERVICE_PRECONDITION=hadoop-namenode:9870
    volumes:
     - ./hadoop/config/core-site.xml:/opt/hadoop/etc/hadoop/core-site.xml
     - ./hadoop/config/hdfs-site-datanode-1.xml:/opt/hadoop/etc/hadoop/hdfs-site.xml
     - ./hadoop/datanode_entrypoint.sh:/datanode_entrypoint.sh
    entrypoint: ["/bin/bash", "/datanode_entrypoint.sh"]
    command: ["hdfs", "datanode"]
    networks:
      - cheburnet


  hadoop-datanode-2:
    image: apache/hadoop:3.4.1
    container_name: hadoop-datanode-2
    hostname: hadoop-datanode-2
    user: "root"
    restart: always
    platform: linux/amd64
    deploy:
     resources:
       limits:
         cpus: "1.0"
         memory: "2g"
    shm_size: 10G
    depends_on:
      - hadoop-namenode
    ports:
      - "9865:9865"
      - "9971:9971"
    environment:
      - SERVICE_PRECONDITION=hadoop-namenode:9870
    volumes:
     - ./hadoop/config/core-site.xml:/opt/hadoop/etc/hadoop/core-site.xml
     - ./hadoop/config/hdfs-site-datanode-2.xml:/opt/hadoop/etc/hadoop/hdfs-site.xml
     - ./hadoop/datanode_entrypoint.sh:/datanode_entrypoint.sh
    entrypoint: ["/bin/bash", "/datanode_entrypoint.sh"]
    command: ["hdfs", "datanode"]
    networks:
      - cheburnet
      
  hadoop-datanode-3:
    image: apache/hadoop:3.4.1
    container_name: hadoop-datanode-3
    hostname: hadoop-datanode-3
    user: "root"
    restart: always
    platform: linux/amd64
    deploy:
     resources:
       limits:
         cpus: "1.0"
         memory: "2g"
    shm_size: 10G
    depends_on:
      - hadoop-namenode
    ports:
      - "9866:9866"
      - "9972:9972"
    environment:
      - SERVICE_PRECONDITION=hadoop-namenode:9870
    volumes:
     - ./hadoop/config/core-site.xml:/opt/hadoop/etc/hadoop/core-site.xml
     - ./hadoop/config/hdfs-site-datanode-3.xml:/opt/hadoop/etc/hadoop/hdfs-site.xml
     - ./hadoop/datanode_entrypoint.sh:/datanode_entrypoint.sh
    entrypoint: ["/bin/bash", "/datanode_entrypoint.sh"]
    command: ["hdfs", "datanode"]
    networks:
      - cheburnet
      
      
  spark-master:
    image: bitnami/spark:3.5.4
    container_name: spark-master
    hostname: spark-master
    ports:
      - '8090:8080'
      - '7077:7077'
    working_dir: /app
    volumes:
      - ./hadoop/spark-app:/app
    environment:
      INIT_DAEMON_STEP: setup_spark
    networks:
      - cheburnet

  spark-worker:
    image: bitnami/spark:3.5.4
    container_name: spark-worker
    hostname: spark-worker
    depends_on:
      - spark-master
    ports:
      - '8038:8081'
    environment:
      - SPARK_MASTER=spark://spark-master:7077
    networks:
      - cheburnet



networks:
  cheburnet:
    driver: bridge